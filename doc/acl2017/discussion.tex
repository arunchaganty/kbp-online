\section{Discussion}
\label{sec:discussion}

\fake{This section is also currently incoherent, so omitted.}
% %(1 page)
% 
% \paragraph{Related work.}
% 
% Cite a bunch of IR evaluation related work on estimation, pooling bias and variance reduction. Weber's thesis for score standardization and pooling bias.
% 
% Cite ACE tasks -- KBP system papers for evaluation methodology. 
% 
% Cite Ellie Pavlick's gun violence database -- also say that KBP is a whole-body workout for NLP -- main distinction is that we care about rigorous evaluation of submissions -- set up for helping development -- plan to do event extraction at a later point in time.
% 
% Cite Dan Klein's paper on statistical significance for NLP.
% 
% \paragraph{Discussion.}
% 
% We started this work by challenging what was needed to improve on KBP.
% Identified the difficulty of evaluating development as a cause.
% Online platform as a solution.
% 
% Some caveats of this platform -- the scores are not stable --  statistically within confidence interval, thus scores should not change much; furthermore, we believe results should be quoted with confidence intervals anyways.
% 
% Only part of the problem.
% A large dataset is equally important.
% Presence of this platform allows us to decouple dataset creation from task. -- e.g. can use and evaluate distantly supervised datasets more easily.
